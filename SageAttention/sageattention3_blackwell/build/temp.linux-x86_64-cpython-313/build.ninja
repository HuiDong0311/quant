ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda-12.8/bin/nvcc

cflags = -pthread -B /home/ubuntu/miniconda3/envs/sage3/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/ubuntu/miniconda3/envs/sage3/include -fPIC -O2 -isystem /home/ubuntu/miniconda3/envs/sage3/include -fPIC -I/home/ubuntu/SageAttention/sageattention3_blackwell/sageattn3 -I/home/ubuntu/SageAttention/sageattention3_blackwell/csrc/cutlass/include -I/home/ubuntu/SageAttention/sageattention3_blackwell/csrc/cutlass/tools/util/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda-12.8/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda-12.8/include -I/home/ubuntu/miniconda3/envs/sage3/include/python3.13 -c
post_cflags = -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fp4quant_cuda
cuda_cflags = -I/home/ubuntu/SageAttention/sageattention3_blackwell/sageattn3 -I/home/ubuntu/SageAttention/sageattention3_blackwell/csrc/cutlass/include -I/home/ubuntu/SageAttention/sageattention3_blackwell/csrc/cutlass/tools/util/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda-12.8/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include -I/home/ubuntu/miniconda3/envs/sage3/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda-12.8/include -I/home/ubuntu/miniconda3/envs/sage3/include/python3.13 -c
cuda_post_cflags = -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math --ptxas-options=--verbose,--warn-on-local-memory-usage -lineinfo -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG -DQBLKSIZE=128 -DKBLKSIZE=128 -DCTA256 -DDQINRMEM -DEXECMODE=0 -gencode arch=compute_100a,code=sm_100a --threads 4 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fp4quant_cuda
cuda_dlink_post_cflags = 
sycl_dlink_post_cflags = 
ldflags = 

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc --generate-dependencies-with-compile --dependency-output $out.d $cuda_cflags -c $in -o $out $cuda_post_cflags







build /home/ubuntu/SageAttention/sageattention3_blackwell/build/temp.linux-x86_64-cpython-313/sageattn3/quantization/fp4_quantization_4d.o: cuda_compile /home/ubuntu/SageAttention/sageattention3_blackwell/sageattn3/quantization/fp4_quantization_4d.cu








